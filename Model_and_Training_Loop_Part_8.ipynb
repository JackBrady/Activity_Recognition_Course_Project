{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model and Training Loop Part 8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Pjh2zFkwGj",
        "colab_type": "text"
      },
      "source": [
        "Pre-Processing Code Adapted From the Following Repo:\n",
        "https://github.com/jfzhang95/pytorch-video-recognition\n",
        "\n",
        "Pre-Trained R3D Model Taken From The Following Repo:\n",
        "https://github.com/kenshohara/3D-ResNets-PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwDIH2IWk6yj",
        "colab_type": "text"
      },
      "source": [
        "Code below specifying the 3D Resnet model taken from the aformentioned repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ty3CulOlSx2E",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from functools import partial\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def get_inplanes():\n",
        "    return [64, 128, 256, 512]\n",
        "\n",
        "'''\n",
        "3D conv layers\n",
        "'''\n",
        "def conv3x3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv3d(in_planes,\n",
        "                     out_planes,\n",
        "                     kernel_size=3,\n",
        "                     stride=stride,\n",
        "                     padding=1,\n",
        "                     bias=False)\n",
        "\n",
        "\n",
        "def conv1x1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv3d(in_planes,\n",
        "                     out_planes,\n",
        "                     kernel_size=1,\n",
        "                     stride=stride,\n",
        "                     bias=False)\n",
        "\n",
        "\n",
        "'''\n",
        "Resnet Block\n",
        "'''\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "'''\n",
        "Full 3D Resnet\n",
        "'''\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 block,\n",
        "                 layers,\n",
        "                 block_inplanes,\n",
        "                 n_input_channels=3,\n",
        "                 conv1_t_size=7,\n",
        "                 conv1_t_stride=1,\n",
        "                 no_max_pool=False,\n",
        "                 shortcut_type='B',\n",
        "                 widen_factor=1.0,\n",
        "                 n_classes=1039):\n",
        "        super().__init__()\n",
        "\n",
        "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
        "\n",
        "        self.in_planes = block_inplanes[0]\n",
        "        self.no_max_pool = no_max_pool\n",
        "\n",
        "        self.conv1 = nn.Conv3d(n_input_channels,\n",
        "                               self.in_planes,\n",
        "                               kernel_size=(conv1_t_size, 7, 7),\n",
        "                               stride=(conv1_t_stride, 2, 2),\n",
        "                               padding=(conv1_t_size // 2, 3, 3),\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n",
        "                                       shortcut_type)\n",
        "        self.layer2 = self._make_layer(block,\n",
        "                                       block_inplanes[1],\n",
        "                                       layers[1],\n",
        "                                       shortcut_type,\n",
        "                                       stride=2)\n",
        "        self.layer3 = self._make_layer(block,\n",
        "                                       block_inplanes[2],\n",
        "                                       layers[2],\n",
        "                                       shortcut_type,\n",
        "                                       stride=2)\n",
        "        self.layer4 = self._make_layer(block,\n",
        "                                       block_inplanes[3],\n",
        "                                       layers[3],\n",
        "                                       shortcut_type,\n",
        "                                       stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
        "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                nn.init.kaiming_normal_(m.weight,\n",
        "                                        mode='fan_out',\n",
        "                                        nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _downsample_basic_block(self, x, planes, stride):\n",
        "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
        "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
        "                                out.size(3), out.size(4))\n",
        "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
        "            zero_pads = zero_pads.cuda()\n",
        "\n",
        "        out = torch.cat([out.data, zero_pads], dim=1)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
        "            if shortcut_type == 'A':\n",
        "                downsample = partial(self._downsample_basic_block,\n",
        "                                     planes=planes * block.expansion,\n",
        "                                     stride=stride)\n",
        "            else:\n",
        "                downsample = nn.Sequential(\n",
        "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
        "                    nn.BatchNorm3d(planes * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(in_planes=self.in_planes,\n",
        "                  planes=planes,\n",
        "                  stride=stride,\n",
        "                  downsample=downsample))\n",
        "        self.in_planes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.in_planes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        if not self.no_max_pool:\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "'''\n",
        "Function to create model\n",
        "'''\n",
        "def generate(model_depth, **kwargs):\n",
        "    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n",
        "\n",
        "    if model_depth == 10:\n",
        "        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 18:\n",
        "        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 34:\n",
        "        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
        "\n",
        "    return model\n",
        "\n",
        "'''\n",
        "Function to load pretrained model\n",
        "'''\n",
        "def load_pretrained_model(model, pretrain_path, model_name, n_finetune_classes):\n",
        "    if pretrain_path:\n",
        "        print('loading pretrained model {}'.format(pretrain_path))\n",
        "        pretrain = torch.load(pretrain_path, map_location='cpu')\n",
        "\n",
        "        model.load_state_dict(pretrain['state_dict'])\n",
        "        tmp_model = model\n",
        "        if model_name == 'densenet':\n",
        "            tmp_model.classifier = nn.Linear(tmp_model.classifier.in_features,\n",
        "                                             n_finetune_classes)\n",
        "        else:\n",
        "            tmp_model.fc = nn.Linear(tmp_model.fc.in_features,\n",
        "                                     n_finetune_classes)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlKE3JV3lb9w",
        "colab_type": "text"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv3vx50xEWbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "model_depth = 34\n",
        "j = generate(model_depth)\n",
        "model = load_pretrained_model(j, 'r3d34_KM_200ep.pth', 'resnet', 51)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(512, 51)\n",
        "model.train()\n",
        "\n",
        "'''\n",
        "Hyperparameters\n",
        "'''\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "weight_decay = 1e-5\n",
        "learning_rate = 5e-4\n",
        "\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=5e-4, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15], gamma=0.1)\n",
        "\n",
        "model.cuda()\n",
        "loss_function.cuda()\n",
        "\n",
        "'''\n",
        "Preprocessing and dataloaders\n",
        "'''\n",
        "\n",
        "train_dataloader = DataLoader(VideoDataset(dataset='hmdb51', split='train',clip_len=16), batch_size=32, shuffle=True, num_workers=4)\n",
        "val_dataloader   = DataLoader(VideoDataset(dataset='hmdb51', split='val',  clip_len=16), batch_size=32, num_workers=4)\n",
        "test_dataloader  = DataLoader(VideoDataset(dataset='hmdb51', split='test', clip_len=16), batch_size=32, num_workers=4)\n",
        "\n",
        "'''\n",
        "Initializing ist of training performance metrics\n",
        "'''\n",
        "\n",
        "training_loss = []\n",
        "training_acc = []\n",
        "validation_loss = []\n",
        "validation_acc = []\n",
        "\n",
        "\n",
        "'''\n",
        "Training_Loop\n",
        "'''\n",
        "for z in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        probs = nn.Softmax(dim=1)(outputs)\n",
        "        preds = torch.max(probs, 1)[1]\n",
        "        loss = loss_function(outputs, labels)\n",
        "        accuracy = torch.sum(preds == labels.data).item()\n",
        "\n",
        "        print(\"Epoch:\",z, \"Loss:\",loss.item(), \"Accuracy:\", accuracy/32)\n",
        "        training_loss.append(loss.item())\n",
        "        training_acc.append(accuracy/32)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if i % 40 == 0 and i != 0:\n",
        "            with torch.no_grad():\n",
        "              total_val_loss = 0\n",
        "              total_val_acc = 0\n",
        "              model.eval()\n",
        "\n",
        "            m = 0\n",
        "            for j, (inputs, labels) in enumerate(val_dataloader):\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                val_probs = nn.Softmax(dim=1)(outputs)\n",
        "                val_loss = loss_function(outputs, labels)\n",
        "                val_preds = torch.max(val_probs, 1)[1]\n",
        "                total_val_acc += torch.sum(val_preds == labels.data).item()\n",
        "\n",
        "                total_val_loss += val_loss.item()\n",
        "                m += 1\n",
        "\n",
        "            print(\"Validation Loss:\", total_val_loss/m, \"acc:\",total_val_acc/32/m)\n",
        "            validation_loss.append(total_val_loss/m)\n",
        "            validation_acc.append(total_val_acc/32/m)\n",
        "            model.train()\n",
        "            \n",
        "    scheduler.step()\n",
        "\n",
        "    '''\n",
        "    Saving model and performance metrics\n",
        "    '''\n",
        "    torch.save(model.state_dict(), 'R3D_big3.pt')\n",
        "    np.save('Training_Loss_6', np.array(training_loss))\n",
        "    np.save('Training_Accuracy_6', np.array(training_acc))\n",
        "    np.save('Val_Loss_6', np.array(validation_loss))\n",
        "    np.save('Val_Accuracy_6', np.array(validation_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7tK6iHYlhji",
        "colab_type": "text"
      },
      "source": [
        "**Test Set Performance**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2twb2flm4u1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "m = 0\n",
        "with torch.no_grad():\n",
        "              total_test_loss = 0\n",
        "              total_test_acc = 0\n",
        "              model.eval()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "for j, (inputs, labels) in enumerate(test_dataloader):\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    test_probs = nn.Softmax(dim=1)(outputs)\n",
        "    test_loss = loss_function(outputs, labels)\n",
        "    preds = torch.max(test_probs, 1)[1]\n",
        "    print(test_loss)\n",
        "\n",
        "    total_test_loss += test_loss.item()\n",
        "    total_test_acc += (torch.sum(preds == labels.data).item() / len(labels))\n",
        "    m += 1\n",
        "\n",
        "print('Test Loss:', total_test_loss/m)\n",
        "print('Test Accuracy:', total_test_acc / m)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}