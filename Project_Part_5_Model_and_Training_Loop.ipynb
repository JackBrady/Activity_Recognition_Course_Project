{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Part 5 Model and Training Loop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBmag6gcfBTz",
        "colab_type": "text"
      },
      "source": [
        "Pretrained 3D convnet and the pre-processing code to get dataset adapted from the following repo: https://github.com/jfzhang95/pytorch-video-recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guu2rAh6hRKe",
        "colab_type": "text"
      },
      "source": [
        "**Model Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpl0JaRMSIHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class C3D(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(C3D, self).__init__()\n",
        "\n",
        "        '''\n",
        "        Pretrained feature extractor\n",
        "        '''\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
        "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
        "        self.fc6 = nn.Linear(8192, 4096)\n",
        "        self.fc7 = nn.Linear(4096, 4096)\n",
        "\n",
        "        '''\n",
        "        Trained Layer\n",
        "        '''\n",
        "        self.fc8 = nn.Linear(4096, num_classes)\n",
        "        '''\n",
        "        Xavier initialization\n",
        "        '''\n",
        "        torch.nn.init.xavier_uniform_(self.fc8.weight)\n",
        "\n",
        "        if pretrained:\n",
        "            self.__load_pretrained_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.relu(self.conv3a(x))\n",
        "        x = self.relu(self.conv3b(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.relu(self.conv4a(x))\n",
        "        x = self.relu(self.conv4b(x))\n",
        "        x = self.pool4(x)\n",
        "        x = self.relu(self.conv5a(x))\n",
        "        x = self.relu(self.conv5b(x))\n",
        "        x = self.pool5(x)\n",
        "        x = x.view(-1, 8192)\n",
        "        x = self.relu(self.fc6(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc7(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc8(x)\n",
        "        return logits\n",
        "\n",
        "    def __load_pretrained_weights(self):\n",
        "        corresp_name = {\n",
        "                        \"features.0.weight\": \"conv1.weight\",\n",
        "                        \"features.0.bias\": \"conv1.bias\",\n",
        "                        \"features.3.weight\": \"conv2.weight\",\n",
        "                        \"features.3.bias\": \"conv2.bias\",\n",
        "                        \"features.6.weight\": \"conv3a.weight\",\n",
        "                        \"features.6.bias\": \"conv3a.bias\",\n",
        "                        \"features.8.weight\": \"conv3b.weight\",\n",
        "                        \"features.8.bias\": \"conv3b.bias\",\n",
        "                        \"features.11.weight\": \"conv4a.weight\",\n",
        "                        \"features.11.bias\": \"conv4a.bias\",\n",
        "                        \"features.13.weight\": \"conv4b.weight\",\n",
        "                        \"features.13.bias\": \"conv4b.bias\",\n",
        "                        \"features.16.weight\": \"conv5a.weight\",\n",
        "                        \"features.16.bias\": \"conv5a.bias\",\n",
        "                        \"features.18.weight\": \"conv5b.weight\",\n",
        "                        \"features.18.bias\": \"conv5b.bias\",\n",
        "                        \"classifier.0.weight\": \"fc6.weight\",\n",
        "                        \"classifier.0.bias\": \"fc6.bias\",\n",
        "                        \"classifier.3.weight\": \"fc7.weight\",\n",
        "                        \"classifier.3.bias\": \"fc7.bias\",\n",
        "                        }\n",
        "\n",
        "        p_dict = torch.load('c3d-pretrained.pth')\n",
        "        s_dict = self.state_dict()\n",
        "        for name in p_dict:\n",
        "            if name not in corresp_name:\n",
        "                continue\n",
        "            s_dict[corresp_name[name]] = p_dict[name]\n",
        "        self.load_state_dict(s_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0hw8lWBhUfS",
        "colab_type": "text"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1AthFLCrKO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "num_epochs = 35\n",
        "model.train()\n",
        "\n",
        "model = C3D(num_classes=51, pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc8 = nn.Linear(4096, 51)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc8.parameters(), lr=5e-4, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15,25], gamma=0.1)\n",
        "\n",
        "model.cuda()\n",
        "loss_function.cuda()\n",
        "\n",
        "'''\n",
        "Preprocessing and dataloaders\n",
        "'''\n",
        "train_dataloader = DataLoader(VideoDataset(dataset='hmdb51', split='train',clip_len=16), batch_size=32, shuffle=True, num_workers=4)\n",
        "val_dataloader   = DataLoader(VideoDataset(dataset='hmdb51', split='val',  clip_len=16), batch_size=32, num_workers=4)\n",
        "test_dataloader  = DataLoader(VideoDataset(dataset='hmdb51', split='test', clip_len=16), batch_size=32, num_workers=4)\n",
        "\n",
        "training_loss = []\n",
        "training_acc = []\n",
        "validation_loss = []\n",
        "validation_acc = []\n",
        "\n",
        "for z in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        probs = nn.Softmax(dim=1)(outputs)\n",
        "        preds = torch.max(probs, 1)[1]\n",
        "        loss = loss_function(outputs, labels)\n",
        "        accuracy = torch.sum(preds == labels.data)\n",
        "\n",
        "        print(\"Epoch:\",z, \"Loss:\",loss.item())\n",
        "        training_loss.append(loss.item())\n",
        "        training_acc.append(accuracy.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if i % 40 == 0:\n",
        "            with torch.no_grad():\n",
        "              total_val_loss = 0\n",
        "              total_val_acc = 0\n",
        "              model.eval()\n",
        "\n",
        "            m = 0\n",
        "            for j, (inputs, labels) in enumerate(val_dataloader):\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                val_probs = nn.Softmax(dim=1)(outputs)\n",
        "                val_loss = loss_function(outputs, labels)\n",
        "                val_preds = torch.max(val_probs, 1)[1]\n",
        "                total_val_acc += torch.sum(val_preds == labels.data).item()\n",
        "\n",
        "                total_val_loss += val_loss.item()\n",
        "                m += 1\n",
        "\n",
        "            print(\"Validation Loss:\", total_val_loss/m)\n",
        "            validation_loss.append(total_val_loss/m)\n",
        "            validation_acc.append(total_val_acc/m)\n",
        "            model.train()\n",
        "            \n",
        "    scheduler.step()\n",
        "    torch.save(model.state_dict(), 'c3d_hdm51_part2.pt')\n",
        "    np.save('Training_Loss_2', np.array(training_loss))\n",
        "    np.save('Training_Accuracy_2', np.array(training_acc))\n",
        "    np.save('Val_Loss_2', np.array(validation_loss))\n",
        "    np.save('Val_Accuracy_2', np.array(validation_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnTmeSP6eD77",
        "colab_type": "text"
      },
      "source": [
        "**Test Set Performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8I71txzFaSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = 0\n",
        "with torch.no_grad():\n",
        "              total_test_loss = 0\n",
        "              total_test_acc = 0\n",
        "              model.eval()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "for j, (inputs, labels) in enumerate(test_dataloader):\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    test_probs = nn.Softmax(dim=1)(outputs)\n",
        "    test_loss = loss_function(outputs, labels)\n",
        "    preds = torch.max(test_probs, 1)[1]\n",
        "    print(test_loss)\n",
        "\n",
        "    total_test_loss += test_loss.item()\n",
        "    total_test_acc += torch.sum(preds == labels.data).item()\n",
        "    m += 1\n",
        "\n",
        "print('Test Loss:', total_test_loss/m)\n",
        "print('Test Accuracy:', total_test_acc / m)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}