{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pre-Processing and Training Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f5kA8tOHH9e",
        "colab_type": "text"
      },
      "source": [
        "I am using the hmdb51 dataset and a C3d model where the first n-1 layers are pre-trained and being used as a feature extractor. The pre-processing code to get the dataset as well as the pretrained C3D model were adapted from the following repo:\n",
        "https://github.com/jfzhang95/pytorch-video-recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCTP7Tj6tZmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data = VideoDataset(dataset='hmdb51', split='train', clip_len=8, preprocess=True)\n",
        "train_loader = DataLoader(train_data, batch_size=100, shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpl0JaRMSIHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class C3D(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(C3D, self).__init__()\n",
        "\n",
        "        '''\n",
        "        Pretrained feature extractor\n",
        "        '''\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
        "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
        "        self.fc6 = nn.Linear(8192, 4096)\n",
        "        self.fc7 = nn.Linear(4096, 4096)\n",
        "\n",
        "        '''\n",
        "        Trained Layer\n",
        "        '''\n",
        "        self.fc8 = nn.Linear(4096, num_classes)\n",
        "\n",
        "        if pretrained:\n",
        "            self.__load_pretrained_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.relu(self.conv3a(x))\n",
        "        x = self.relu(self.conv3b(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.relu(self.conv4a(x))\n",
        "        x = self.relu(self.conv4b(x))\n",
        "        x = self.pool4(x)\n",
        "        x = self.relu(self.conv5a(x))\n",
        "        x = self.relu(self.conv5b(x))\n",
        "        x = self.pool5(x)\n",
        "        x = x.view(-1, 8192)\n",
        "        x = self.relu(self.fc6(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc7(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc8(x)\n",
        "        return logits\n",
        "\n",
        "    def __load_pretrained_weights(self):\n",
        "        corresp_name = {\n",
        "                        \"features.0.weight\": \"conv1.weight\",\n",
        "                        \"features.0.bias\": \"conv1.bias\",\n",
        "                        \"features.3.weight\": \"conv2.weight\",\n",
        "                        \"features.3.bias\": \"conv2.bias\",\n",
        "                        \"features.6.weight\": \"conv3a.weight\",\n",
        "                        \"features.6.bias\": \"conv3a.bias\",\n",
        "                        \"features.8.weight\": \"conv3b.weight\",\n",
        "                        \"features.8.bias\": \"conv3b.bias\",\n",
        "                        \"features.11.weight\": \"conv4a.weight\",\n",
        "                        \"features.11.bias\": \"conv4a.bias\",\n",
        "                        \"features.13.weight\": \"conv4b.weight\",\n",
        "                        \"features.13.bias\": \"conv4b.bias\",\n",
        "                        \"features.16.weight\": \"conv5a.weight\",\n",
        "                        \"features.16.bias\": \"conv5a.bias\",\n",
        "                        \"features.18.weight\": \"conv5b.weight\",\n",
        "                        \"features.18.bias\": \"conv5b.bias\",\n",
        "                        \"classifier.0.weight\": \"fc6.weight\",\n",
        "                        \"classifier.0.bias\": \"fc6.bias\",\n",
        "                        \"classifier.3.weight\": \"fc7.weight\",\n",
        "                        \"classifier.3.bias\": \"fc7.bias\",\n",
        "                        }\n",
        "\n",
        "        p_dict = torch.load('c3d-pretrained.pth')\n",
        "        s_dict = self.state_dict()\n",
        "        for name in p_dict:\n",
        "            if name not in corresp_name:\n",
        "                continue\n",
        "            s_dict[corresp_name[name]] = p_dict[name]\n",
        "        self.load_state_dict(s_dict)\n",
        "\n",
        "    def __init_weight(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                torch.nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-tnXu70INJj",
        "colab_type": "text"
      },
      "source": [
        "**Training Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh3hJxqkIRSs",
        "colab_type": "text"
      },
      "source": [
        "I trained the model for 20 epochs using Adam optimizer with a learning rate of 1e-3 and a batch size of 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1AthFLCrKO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "lr = 1e-3\n",
        "\n",
        "model = C3D(num_classes=51, pretrained=True)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc8 = nn.Linear(4096, 51)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc8.parameters(), lr=3e-4)\n",
        "\n",
        "model.cuda()\n",
        "criterion.cuda()\n",
        "\n",
        "train_dataloader = DataLoader(VideoDataset(dataset='hmdb51', split='train',clip_len=16), batch_size=32, shuffle=True, num_workers=4)\n",
        "val_dataloader   = DataLoader(VideoDataset(dataset='hmdb51', split='val',  clip_len=16), batch_size=32, num_workers=4)\n",
        "test_dataloader  = DataLoader(VideoDataset(dataset='hmdb51', split='test', clip_len=16), batch_size=32, num_workers=4)\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for z in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.cuda()\n",
        "        print(inputs.shape)\n",
        "        labels = labels.cuda()\n",
        "        print(labels.shape)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        probs = nn.Softmax(dim=1)(outputs)\n",
        "        preds = torch.max(probs, 1)[1]\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        print(\"Epoch:\",z, \"Loss:\",loss.item())\n",
        "        training_loss.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if i % 40 == 0:\n",
        "            with torch.no_grad():\n",
        "              total_val_loss = 0\n",
        "              model.eval()\n",
        "\n",
        "            m = 0\n",
        "            for j, (inputs, labels) in enumerate(val_dataloader):\n",
        "                inputs = inputs.cuda()\n",
        "                print(inputs.shape)\n",
        "                labels = labels.cuda()\n",
        "                print(labels.shape)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                val_probs = nn.Softmax(dim=1)(outputs)\n",
        "                val_preds = torch.max(val_probs, 1)[1]\n",
        "                val_loss = criterion(outputs, labels)\n",
        "\n",
        "                total_val_loss += val_loss.item()\n",
        "                m += 1\n",
        "\n",
        "            validation_loss.append(total_val_loss/m)\n",
        "            model.train()\n",
        "\n",
        "    torch.save(model.state_dict(), 'c3d_hdm51.pt')\n",
        "    np.save('Training_Loss', np.array(training_loss))\n",
        "    np.save('Val_loss', np.array(validation_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}